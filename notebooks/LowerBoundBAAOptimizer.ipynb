{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bab4e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import notebook as ntqdm\n",
    "import itertools as it\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5457c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAA_EPSILON = 1E-30\n",
    "def apply_penalty(alphas, L_i, l2):\n",
    "    power = -L_i * l2\n",
    "    log_alphas = np.log(alphas) + power\n",
    "    mla = np.max(log_alphas)\n",
    "    probs = np.exp(log_alphas - mla)\n",
    "    probs /= np.sum(probs)\n",
    "    return probs\n",
    "\n",
    "def score_lambda2(alphas, L_i, L_target, l2):\n",
    "    probs = apply_penalty(alphas, L_i, l2)\n",
    "    return np.sign(L_target - np.dot(probs, L_i))\n",
    "\n",
    "def find_lambda2_bs(alphas, L_i, L_target):\n",
    "    lb = 0.0\n",
    "    ub = 1.0\n",
    "    while score_lambda2(alphas, L_i, L_target, ub) < 0:\n",
    "        ub *= 2\n",
    "    \n",
    "    num_iterations = 100\n",
    "    for i in range(num_iterations):\n",
    "        mid = (lb + ub) / 2\n",
    "        sign = score_lambda2(alphas, L_i, L_target, mid)\n",
    "        if np.abs(sign) < BAA_EPSILON:\n",
    "            return mid, apply_penalty(alphas, L_i, mid)\n",
    "        elif sign < 0:\n",
    "            lb = mid\n",
    "        else:\n",
    "            ub = mid\n",
    "    \n",
    "    return mid, apply_penalty(alphas, L_i, mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48c965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(P_ji, Q, L_i, D_i, beta):\n",
    "    Q = np.reshape(Q, (1, -1))\n",
    "    denominator = np.reshape(np.sum(P_ji * Q, axis=1), (-1, 1))\n",
    "    denominator[denominator < BAA_EPSILON] = BAA_EPSILON\n",
    "    return (np.sum(Q * P_ji * np.log(P_ji / denominator)) - (beta * np.dot(Q, D_i))) / np.dot(Q, L_i)\n",
    "\n",
    "def get_score_theoretical(P_ji, Q, Q_prev, L_target, D_i, beta):\n",
    "    Q = np.reshape(Q, (1, -1))\n",
    "    Q_prev = np.reshape(Q_prev, (1, -1))\n",
    "    denominator = np.reshape(np.sum(P_ji * Q_prev, axis=1), (-1, 1))\n",
    "    denominator[denominator < BAA_EPSILON] = BAA_EPSILON\n",
    "    Q_prev = np.clip(Q_prev, BAA_EPSILON, 1)\n",
    "    W_ji = (Q_prev * P_ji) / denominator\n",
    "    return (np.sum(Q * P_ji * (np.log(W_ji) - np.log(Q))) - beta * np.dot(Q, D_i)) / L_target\n",
    "\n",
    "def get_log_alphas(P_ji, Q, D_i, beta):\n",
    "    Q = np.reshape(Q, (1, -1))\n",
    "    denominator = np.reshape(np.sum(P_ji * Q, axis=1), (-1, 1))\n",
    "    denominator[denominator < BAA_EPSILON] = BAA_EPSILON\n",
    "    return np.sum(P_ji * np.log(Q * P_ji / denominator), axis=0) - beta * D_i\n",
    "\n",
    "def do_baa_step(P_ji, Q, L_target, beta, L_i, D_i):\n",
    "    log_alphas = get_log_alphas(P_ji, Q, D_i, beta)\n",
    "    mla = np.max(log_alphas)\n",
    "    alphas = np.exp(log_alphas - mla)\n",
    "    l2, new_Q = find_lambda2_bs(alphas, L_i, L_target)\n",
    "    return new_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640faa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_BAA_params(l: float, BAA_N: int, verbose: bool = True):\n",
    "    if verbose:\n",
    "        print(f'Computing BAA transition probs {BAA_N-1}x{BAA_N} (~2 ** %.1f)' % (np.log2(BAA_N * (BAA_N-1))))\n",
    "    t0 = time.time()\n",
    "    I = np.arange(1, BAA_N)\n",
    "    J = np.arange(0, BAA_N)\n",
    "    IJ, JI = np.meshgrid(I, J)\n",
    "    P_ji = np.clip(stats.poisson(IJ * l).pmf(JI), BAA_EPSILON, 1)\n",
    "    if verbose:\n",
    "        print('That took %.1f seconds' % (time.time() - t0))\n",
    "\n",
    "    D_i = P_ji[0, :]\n",
    "    L_i = I\n",
    "    return P_ji, D_i, L_i\n",
    "\n",
    "def generate_optimized_distribution(l: float, L_target: float, beta: float, verbose: bool = True, \n",
    "                                    step_limit: int = 100, delta: float = 0.005, BAA_N: int = 512):\n",
    "    '''\n",
    "    Uses the weighted version of the Blahut-Arimoto algorithm to generate a potential distribution for an MD07-type code.\n",
    "    '''\n",
    "    P_ji, D_i, L_i = generate_BAA_params(l, BAA_N, verbose)\n",
    "    Q = np.ones(BAA_N - 1)\n",
    "    steps = range(step_limit)\n",
    "    if verbose:\n",
    "        steps = ntqdm.trange(step_limit)\n",
    "    for i in steps:\n",
    "        next_Q = do_baa_step(P_ji, Q, L_target, beta, L_i, D_i)\n",
    "        d = np.max(np.log(Q / next_Q))\n",
    "        if d < delta:\n",
    "            break\n",
    "        Q = next_Q\n",
    "    if verbose:\n",
    "        print(f'The expected score of this distribution is {get_score(P_ji, next_Q, L_i, D_i, beta)}, and it is at most {d} from optimal.')\n",
    "    return next_Q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
